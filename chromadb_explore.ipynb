{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b159d3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddeba291",
   "metadata": {},
   "source": [
    "Generative AI Review Chatbot Project Design\n",
    "This project outlines the design for a Generative AI chatbot that leverages customer review comments to provide answers, using Langchain for orchestration, ChromaDB as a vector store, and Google's Gemini LLMs.\n",
    "\n",
    "Project Goals:\n",
    "Ingest diverse review data: Handle comments stored in CSV, TXT, and JSON formats.\n",
    "\n",
    "Create a searchable knowledge base: Utilize ChromaDB to store vector embeddings of review comments.\n",
    "\n",
    "Implement Retrieval Augmented Generation (RAG): Combine retrieval from ChromaDB with Gemini LLM generation for context-aware responses.\n",
    "\n",
    "Provide a conversational interface: Enable users to query the review data through a chatbot.\n",
    "\n",
    "Project Structure:\n",
    "generative_ai_review_chatbot/\n",
    "├── data/\n",
    "│   ├── reviews.csv         # Example review data in CSV format\n",
    "│   ├── reviews.txt         # Example review data in plain text\n",
    "│   └── reviews.json        # Example review data in JSON format\n",
    "├── chroma_db/              # Directory for ChromaDB persistence\n",
    "├── src/\n",
    "│   ├── data_ingestion.py   # Script for reading, processing, and embedding data into ChromaDB\n",
    "│   ├── rag_chatbot.py      # Script for the RAG-powered chatbot\n",
    "│   ├── utils.py            # Utility functions (e.g., environment variable loading)\n",
    "│   └── main.py             # Main entry point for the application\n",
    "├── requirements.txt        # Python dependencies\n",
    "├── README.md               # Project documentation and instructions\n",
    "└── .env                    # Environment variables (e.g., GOOGLE_API_KEY)\n",
    "\n",
    "Component Breakdown and Detailed Design:\n",
    "1. data/\n",
    "This directory will contain your raw review data in various formats. For demonstration purposes, you'd populate these with sample review comments.\n",
    "\n",
    "reviews.csv:\n",
    "\n",
    "review_id,product_id,rating,comment\n",
    "101,P001,5,\"This product is amazing! Highly recommend for its durability and features.\"\n",
    "102,P001,3,\"It's okay, but I expected more from the battery life. Good price though.\"\n",
    "103,P002,4,\"Great value for money. The setup was a bit tricky, but customer support was helpful.\"\n",
    "\n",
    "reviews.txt: Each line could be a separate review comment.\n",
    "\n",
    "The customer service was excellent, very quick to respond.\n",
    "I love the new design, very sleek and modern.\n",
    "Could improve on the delivery time, it took longer than expected.\n",
    "\n",
    "reviews.json: A list of JSON objects, each representing a review.\n",
    "\n",
    "[\n",
    "  {\"id\": \"R001\", \"text\": \"Fantastic product, exceeded my expectations in every way.\"},\n",
    "  {\"id\": \"R002\", \"text\": \"The quality is decent for the price, but the user interface is a bit clunky.\"},\n",
    "  {\"id\": \"R003\", \"text\": \"Had an issue with shipping, but the item itself is perfect.\"}\n",
    "]\n",
    "\n",
    "2. chroma_db/\n",
    "This directory will be created by ChromaDB to persist your vector store, ensuring that embeddings are not lost when the application restarts.\n",
    "\n",
    "3. src/data_ingestion.py\n",
    "This script handles the preparation of review data for the vector database.\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load GOOGLE_API_KEY from .env\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = '../data'\n",
    "CHROMA_PERSIST_DIR = '../chroma_db'\n",
    "COLLECTION_NAME = 'review_comments'\n",
    "EMBEDDING_MODEL = 'models/embedding-001' # Recommended Gemini embedding model\n",
    "\n",
    "def load_reviews_from_csv(file_path):\n",
    "    \"\"\"Loads review comments from a CSV file.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Assuming 'comment' column contains the review text\n",
    "    return df['comment'].tolist()\n",
    "\n",
    "def load_reviews_from_txt(file_path):\n",
    "    \"\"\"Loads review comments from a TXT file (one comment per line).\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def load_reviews_from_json(file_path):\n",
    "    \"\"\"Loads review comments from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    # Assuming each object has a 'text' key for the review content\n",
    "    return [item['text'] for item in data if 'text' in item]\n",
    "\n",
    "def ingest_data_to_chroma():\n",
    "    \"\"\"\n",
    "    Reads review data from various formats, chunks it,\n",
    "    generates embeddings, and stores them in ChromaDB.\n",
    "    \"\"\"\n",
    "    all_reviews = []\n",
    "\n",
    "    # Load from CSV\n",
    "    csv_path = os.path.join(DATA_DIR, 'reviews.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        all_reviews.extend(load_reviews_from_csv(csv_path))\n",
    "        print(f\"Loaded {len(all_reviews)} reviews from CSV.\")\n",
    "\n",
    "    # Load from TXT\n",
    "    txt_path = os.path.join(DATA_DIR, 'reviews.txt')\n",
    "    if os.path.exists(txt_path):\n",
    "        all_reviews.extend(load_reviews_from_txt(txt_path))\n",
    "        print(f\"Loaded {len(all_reviews)} reviews from TXT.\")\n",
    "\n",
    "    # Load from JSON\n",
    "    json_path = os.path.join(DATA_DIR, 'reviews.json')\n",
    "    if os.path.exists(json_path):\n",
    "        all_reviews.extend(load_reviews_from_json(json_path))\n",
    "        print(f\"Loaded {len(all_reviews)} reviews from JSON.\")\n",
    "\n",
    "    if not all_reviews:\n",
    "        print(\"No review data found to ingest. Please populate the 'data' directory.\")\n",
    "        return\n",
    "\n",
    "    # Text Splitting\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    chunks = text_splitter.create_documents(all_reviews)\n",
    "    print(f\"Split {len(all_reviews)} reviews into {len(chunks)} chunks.\")\n",
    "\n",
    "    # Initialize Google Generative AI Embeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "    # Create and persist ChromaDB vector store\n",
    "    # This will create the 'chroma_db' directory if it doesn't exist\n",
    "    print(\"Creating/updating ChromaDB. This may take a moment...\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=CHROMA_PERSIST_DIR,\n",
    "        collection_name=COLLECTION_NAME\n",
    "    )\n",
    "    vectorstore.persist() # Ensure data is written to disk\n",
    "    print(f\"Data successfully ingested into ChromaDB collection '{COLLECTION_NAME}'.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ingest_data_to_chroma()\n",
    "\n",
    "4. src/rag_chatbot.py\n",
    "This script sets up the Langchain RAG chain and provides a simple interface for the chatbot.\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load GOOGLE_API_KEY from .env\n",
    "\n",
    "# Configuration\n",
    "CHROMA_PERSIST_DIR = '../chroma_db'\n",
    "COLLECTION_NAME = 'review_comments'\n",
    "LLM_MODEL = 'gemini-pro' # Or 'gemini-1.5-pro-latest', 'gemini-1.5-flash-latest'\n",
    "EMBEDDING_MODEL = 'models/embedding-001'\n",
    "\n",
    "def setup_rag_chain():\n",
    "    \"\"\"\n",
    "    Sets up the Langchain RAG chain with Gemini LLM and ChromaDB.\n",
    "    \"\"\"\n",
    "    # Initialize Google Generative AI Embeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "    # Load existing ChromaDB vector store\n",
    "    # Ensure the collection exists and has been populated by data_ingestion.py\n",
    "    try:\n",
    "        vectorstore = Chroma(\n",
    "            persist_directory=CHROMA_PERSIST_DIR,\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=COLLECTION_NAME\n",
    "        )\n",
    "        print(f\"Loaded ChromaDB from '{CHROMA_PERSIST_DIR}' with collection '{COLLECTION_NAME}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ChromaDB: {e}. Ensure data has been ingested.\")\n",
    "        print(\"Run `python src/data_ingestion.py` first.\")\n",
    "        return None\n",
    "\n",
    "    # Create a retriever from the vector store\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # Retrieve top 3 relevant documents\n",
    "\n",
    "    # Initialize Gemini LLM\n",
    "    llm = ChatGoogleGenerativeAI(model=LLM_MODEL, temperature=0.2)\n",
    "\n",
    "    # Define the prompt for the LLM\n",
    "    # This prompt instructs the LLM to use the retrieved context\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are a helpful assistant that answers questions about product reviews.\n",
    "    Use the following retrieved review comments as context to answer the user's question.\n",
    "    If you don't know the answer based on the provided context, politely state that you don't have enough information.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {input}\n",
    "    \"\"\")\n",
    "\n",
    "    # Create a chain to combine documents with the prompt and LLM\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    # Create the full RAG retrieval chain\n",
    "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "    return retrieval_chain\n",
    "\n",
    "def chat_interface():\n",
    "    \"\"\"Provides a simple command-line interface for the chatbot.\"\"\"\n",
    "    rag_chain = setup_rag_chain()\n",
    "    if not rag_chain:\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Generative AI Review Chatbot ---\")\n",
    "    print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nYour question about reviews: \")\n",
    "        if user_query.lower() in ['exit', 'quit']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            response = rag_chain.invoke({\"input\": user_query})\n",
    "            print(\"\\nChatbot:\", response[\"answer\"])\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Please ensure your GOOGLE_API_KEY is set correctly and the models are accessible.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    chat_interface()\n",
    "\n",
    "5. src/utils.py\n",
    "This file can contain helper functions. For this project, loading environment variables is handled directly in the scripts using dotenv.\n",
    "\n",
    "6. src/main.py\n",
    "This script acts as the main entry point, allowing users to choose between ingesting data or starting the chatbot.\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src directory to path to allow direct imports\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__)))\n",
    "\n",
    "from data_ingestion import ingest_data_to_chroma\n",
    "from rag_chatbot import chat_interface\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the Generative AI Review Chatbot project.\"\"\"\n",
    "    print(\"Welcome to the Generative AI Review Chatbot Project!\")\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Ingest review data (run this first to build/update the knowledge base)\")\n",
    "    print(\"2. Start the chatbot\")\n",
    "    print(\"3. Exit\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"Enter your choice (1, 2, or 3): \")\n",
    "        if choice == '1':\n",
    "            ingest_data_to_chroma()\n",
    "        elif choice == '2':\n",
    "            chat_interface()\n",
    "        elif choice == '3':\n",
    "            print(\"Exiting project. Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "7. requirements.txt\n",
    "langchain==0.2.x # Use the latest stable version\n",
    "langchain-google-genai==0.0.x # Use the latest stable version\n",
    "chromadb==0.5.x # Use the latest stable version\n",
    "pandas==2.2.x\n",
    "python-dotenv==1.0.x\n",
    "tiktoken # For text splitting if using token-based chunking, or just character-based\n",
    "\n",
    "8. .env\n",
    "Create this file in the root directory (generative_ai_review_chatbot/) and add your Google API Key:\n",
    "\n",
    "GOOGLE_API_KEY=\"YOUR_GEMINI_API_KEY_HERE\"\n",
    "\n",
    "Setup and Usage Instructions (README.md content):\n",
    "Clone the repository:\n",
    "\n",
    "git clone <your-repo-url>\n",
    "cd generative_ai_review_chatbot\n",
    "\n",
    "Create a virtual environment:\n",
    "\n",
    "python -m venv venv\n",
    "source venv/bin/activate # On Windows: venv\\Scripts\\activate\n",
    "\n",
    "Install dependencies:\n",
    "\n",
    "pip install -r requirements.txt\n",
    "\n",
    "Set up your Google API Key:\n",
    "\n",
    "Go to Google AI Studio or Google Cloud Console to get your Gemini API Key.\n",
    "\n",
    "Create a .env file in the root directory of the project and add your API key:\n",
    "\n",
    "GOOGLE_API_KEY=\"YOUR_GEMINI_API_KEY_HERE\"\n",
    "\n",
    "Prepare your review data:\n",
    "\n",
    "Place your reviews.csv, reviews.txt, and reviews.json files in the data/ directory. Ensure they follow the expected format (e.g., comment column in CSV, text key in JSON).\n",
    "\n",
    "Ingest data into ChromaDB:\n",
    "\n",
    "Run the main.py script and choose option 1 to ingest the data. This will create vector embeddings and store them in the chroma_db/ directory.\n",
    "\n",
    "python src/main.py\n",
    "\n",
    "(Select 1 for data ingestion)\n",
    "\n",
    "Start the Chatbot:\n",
    "\n",
    "Run the main.py script again and choose option 2 to start the chatbot.\n",
    "\n",
    "python src/main.py\n",
    "\n",
    "(Select 2 to start the chatbot)\n",
    "\n",
    "You can now type questions about your review data, and the chatbot will use the ingested comments to provide answers.\n",
    "\n",
    "Key Considerations and Enhancements:\n",
    "Error Handling: Implement more robust error handling, especially for file operations and API calls.\n",
    "\n",
    "Logging: Add a proper logging mechanism to track the chatbot's activity and debug issues.\n",
    "\n",
    "User Interface: For a more user-friendly experience, consider building a web interface using frameworks like Streamlit or Flask.\n",
    "\n",
    "Advanced Text Splitting: Experiment with different RecursiveCharacterTextSplitter parameters or other text splitting strategies to optimize retrieval.\n",
    "\n",
    "Metadata: When ingesting, consider adding metadata to your chunks (e.g., source_file, product_id, rating). This metadata can be used for more precise filtering during retrieval.\n",
    "\n",
    "Evaluation: For a production-ready system, set up metrics to evaluate the RAG system's performance (e.g., retrieval accuracy, answer relevance).\n",
    "\n",
    "Streaming Responses: Langchain and Gemini support streaming. You could enhance the chatbot to stream responses for a more dynamic user experience.\n",
    "\n",
    "Conversation History: For a more natural conversation, integrate a memory component into the Langchain chain to allow the chatbot to remember previous turns in the conversation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
